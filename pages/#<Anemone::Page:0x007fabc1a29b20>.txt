 
 
 
 
 
 
 seo ruby on rails : bonnes pratiques (1ère partie) • antoine brisset 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
         
  accueil  
  blog  
  contact  
     
  
  
 bonnes pratiques seo sous ruby on rails - 1ère partie 
     seo on-site  
  
     blog seo  >  seo on-site  
 publié le 27 may 2015 
 après avoir passé quelques années à bidouiller des petits scripts en ruby, je me suis lancé l’année dernière dans l’apprentissage de ruby on rails, grâce notamment à  ce livre de stefan wintermeyer , que je recommande d’ailleurs vivement à tous ceux qui seraient désireux d’apprendre les bases de ror. n’étant pas développeur de formation, ce framework est pour moi vraiment intéressant dans le sens où il permet de développer rapidement et sans trop de prise de tête des applications plus ou moins complexes. ayant suffisamment de recul sur le fonctionnement de rails, je vous propose une série d’articles sous forme d’astuces pour optimiser les fondamentaux seo de votre application ruby on rails. c’est parti pour la 1ère partie ! 
 réécriture d'url   par défaut, rails utilise la clé primaire id pour la génération des url. par exemple, s'il reçoit une requête de type get /photos/3, le fichier routes.rb va transmettre la requête au controller “photos_controller”, en passant en paramètre à l'action “show” la valeur de l'id. rails va donc être en mesure de retrouver l'objet associé en recherchant dans le modèle “photo” l'objet ayant pour id “3”.   cela fonctionne très bien, certes, mais ce n'est pas optimal d'un point de vue seo. si j'ai tendance à considérer que l'ajout de mots-clés dans l'url n'est pas impératif en termes de ranking, je pense néanmoins que dans les serp, avoir le mot-clé en gras au lieu d'un simple id est un petit plus visuel qui peut booster votre ctr.   alors, comment faire pour rendre les url plus sexy ? une première solution pourrait être de surcharger la méthode to_param, qui, grosso modo, gère la construction des chemins d'url. quelque chose de ce type, dans le modèle :     def   to_param 
   "  #{  id  }  -  #{  name  .  parameterize  }  " 
 end 
    dans le cas où notre table photos dispose d'une colomne “name”, les url générées pour chaque objet photo reprendront l'id, suivi du nom, lequel aura été débarrassé de tout caractère spécial, via la méthode “parameterize”.   c'est une solution intéressante mais qui présente un gros défaut : avant de lancer la requête sql lui permettant de rechercher à quel objet correspond l'id reçu en paramètre, rails va convertir cet id en entier via la méthode to_i. ce qui signifie, par exemple, que “1-toto” va devenir “1”. vous voyez où je veux en venir ? si quelqu'un s'amuse à générer des url de type “1-lolilol” ou “1-trololo”, rails va quand même renvoyer l'objet ayant pour id “1” et afficher la page, laissant la porte ouverte à des attaques de negative seo à coup de duplicate d'url.   je vous conseille donc d'utiliser un système plus robuste, qui se débarrassera complètement de l'id et reposera sur un autre attribut du modèle. par exemple, dans le cas de notre modèle photo, l'attribut name. on pourrait faire cela “à la main” :     on ajoute un nouvel attribut à notre modèle, par exemple “slug” (il faut prévoir la migration de la base)      rails g migration addslugtophotos slug:string
rake db:migrate
      on l'ajoute à notre liste de paramètres autorisés, au niveau du controller       def   photo_params 
   params  .  required  (  :photo  ).  permit  (  :name  ,   :slug  ) 
 end 
      on valide sa présence lors de chaque nouvel item créé, au niveau du modèle       validates   :slug  ,   presence:   true  ,   uniqueness:   true 
      on modifie la la méthode to_param, au niveau du modèle       def   to_param 
   slug 
 end 
      pour chaque appel à la méthode find, il faudra désormais utiliser la méthode “find by slug” et non plus “find”, puisque cette dernière recherche les enregistrements de la base de données par id.     pour aller beaucoup plus vite, dans cet esprit, il existe une gem très complète :  friendly_id . une fois la gem installée, il suffit de d'ajouter les méthodes de la classe friendlyid à notre modèle     extend   friendlyid 
    puis de spécifier quel attribut sera utilisé pour la génération du slug (ici, “name”)     friendly_id   :name  ,   use: :slugged 
    et enfin, de remplacer la méthode  find  par  friendly.find , chaque fois que vous l'utilisez dans vos vues et/ou controllers.   et voilà ! on se retrouve avec de belles url contenant nos mots-clés. petite précision concernant les url sous rails : par défaut rails utilise les cookies pour stocker les infos de session. donc a priori, vous n'aurez jamais de souci avec des id de session présents dans les url qui pourraient créer du duplicate d'url.   balises title & meta   le contenu de la balise title est l'un des critères seo les plus importants, c'est d'ailleurs  un consensus auprès des référenceurs . dans une application ruby on rails, il faut donc disposer a minima d'un système permettant de personnaliser les balises title et meta (description, robots) pour chaque page / template.   pour faire cela proprement et simplement, on pourrait par exemple s'aider d'une méthode qu'on ajouterait dans le helper de l'application. l'idée étant de ne pas surcharger nos vues. par exemple, on pourrait ajouter une méthode telle que celle-ci dans notre fichier application_helper.rb     def   title  (  title_content  ) 
   if   title_content  .  present?   # si le paramètre title_content est présent 
     title_content   <<   " | mon site"   # le title reprendra la chaîne en paramètre suivie de " | mon site" 
   else 
     "mon site"   # sinon, par défaut, le title sera "mon site" 
   end 
 end 
    dans le layout de l'application, il faudrait donc dynamiser cette partie (ici sous slim) :     title 
   =   yield  (  :title  ) 
    puis, dans chaque vue, utiliser la méthode content_for qui fera appel à notre helper, de cette manière :     =   content_for   :title  ,   title  (  "mon titre avec mots-clés"  ) 
    vous pourriez vous inspirer de ce helper pour gérer, de la même façon, les balises meta description et meta robots.    maj du 01/06/2015    suite à cet  excellent article  publié par le wagon, je vous conseille de définir les valeurs par défaut de vos balises meta dans un fichier yaml à placer directement dans le dossier config/initializers (exemple: meta.rb)     default_title  :   "  mon     site" 
    puis de charger celui-ci dans le fichier environnement.rb :     default_meta   =   yaml  .  load_file  (  rails  .  root  .  join  (  '/config/meta.yml'  )) 
    ce qui vous permettra, dans votre helper, de faire la chose suivante :     def   title  (  title_content  ) 
   if   title_content  .  present? 
     title_content   <<   " | "   +   default_meta  [  'title'  ] 
   else 
     default_meta  [  'title'  ] 
   end 
 end 
    si vous souhaitez faire plus simple (ou aller plus vite, à vous de voir), je vous conseille d'utiliser la gem  meta_tags . elle permet de définir et de personnaliser vos balises title, meta, open graph, twitter cards, hreflang et bien d'autres, que ce soit au niveau de votre controller ou au niveau de votre vue. un outil vraiment très bien pensé, intuitif, qui vous rendra service si vous souhaitez optimiser dans le détail toutes ces balises sans réinventer la roue.   si je reprends mon modèle photo, et que je souhaite par exemple définir les title et meta description de chaque item photo, voici comment je devrai procéder :     d'abord, ajouter la méthode dans le layout de l'application       display_meta_tags   :site   =>   'mon site'  ,   :reverse   =>   true  ,   :separator   =>   "|" 
      puis setter les bonnes variables dans le controller photos_controller#show       def   show 
   @photo   =   photo  .  friendly  .  find  (  params  [  :id  ]) 
   set_meta_tags   :title   =>   '@photo.name'  , 
                 :description   =>   '@photo.name : découvrez ma jolie photo !'  , 
                 :robots   =>   'index, follow' 
 end 
    robots.txt   le fichier robots.txt est un fichier tout bête à première vue et pourtant, c'est celui pour lequel googlebot a le plus d'appétance. en effet, c'est dans celui-ci que sont contenues les directives de crawl de votre site. une erreur de syntaxe, et ça peut être la catastrophe !   pour la gestion de ce fichier, plusieurs options sont possibles sous rails.   1ère option   tout d'abord, vous pouvez créer ce fichier et le placer dans le dossier public de votre application. il sera alors disponible directement à la racine de votre site. oui, mais problème : pour chacun de vos environnements, le contenu de ce fichier sera le même. donc si en prod, vous avez un joli    user-agent: *
allow: /
    … alors votre environnement de préprod contiendra les mêmes directives et risquera de se faire crawler et donc indexer, dans l'éventualité bien sûr où celui-ci n'est pas protégé par authentification (login / mot de passe). pas top donc. passons à la 2ème option.   2ème option   la 2ème option est de loin la meilleure, mais elle nécessite un peu plus de travail. en effet, nous allons utiliser un controller spécifique qui interceptera toutes les requêtes de type get /robots.txt. pour cela, commençons par mettre à jour notre fichier routes.rb     get   '/robots.:format'   =>   'pages#robots' 
    ici, nous allons transmettre la requête à un controller “pages” et plus spécifiquement à l'action “robots”. voyons voir le contenu de notre méthode robots :     def   robots 
   respond_to   :text 
 end 
    rien de bien sorcier, elle s'occupe simplement de “répondre” à la requête en renvoyant un contenu au format texte. passons à notre vue, rendez-vous dans views > pages > robots.text.slim. c'est ici que ça devient intéressant. car, oui, nous allons pouvoir dynamiser notre fichier robots.txt, c'est-à-dire renvoyer un contenu différent selon que l'on soit sur l'environnement de production ou sur l'environnement de développement / staging / recette.     -   if   rails  .  env   ==   "production" 
   =   "user-agent: *  \n  " 
   =   "disallow: /admin" 
 -   else 
   =   "user-agent: *  \n  " 
   =   "noindex: /" 
 end 
    grâce à cette astuce, vous maîtrisez parfaitement votre indexation sur chacun de vos environnements !   a bientôt pour de nouvelles astuces d'optimisation de votre référencement naturel sous ruby on rails.        comments powered by  disqus      
  
 
 
   saint andré lez lille 
 
   06 12 71 82 78 
 
    contact@antoine-brisset.com   
 
 
      
      
      
 
  © 2015 -  antoine brisset 
 
  
 
 
